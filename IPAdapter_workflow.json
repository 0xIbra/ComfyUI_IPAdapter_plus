{
  "last_node_id": 19,
  "last_link_id": 30,
  "nodes": [
    {
      "id": 12,
      "type": "VAEDecode",
      "pos": [
        1430,
        320
      ],
      "size": {
        "0": 140,
        "1": 50
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 12
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            14
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 13,
      "type": "PreviewImage",
      "pos": [
        1430,
        420
      ],
      "size": {
        "0": 323.45098876953125,
        "1": 356.3552551269531
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 14
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 17,
      "type": "IPAdapterApply",
      "pos": [
        790,
        150
      ],
      "size": [
        210,
        98
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 30
        },
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 27
        },
        {
          "name": "clip_vision_output",
          "type": "CLIP_VISION_OUTPUT",
          "link": 28
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            29
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        1
      ]
    },
    {
      "id": 6,
      "type": "LoadImage",
      "pos": [
        120,
        200
      ],
      "size": [
        220,
        300
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            2
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "example.png",
        "image"
      ]
    },
    {
      "id": 2,
      "type": "CLIPVisionEncode",
      "pos": [
        450,
        170
      ],
      "size": [
        250,
        50
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 1
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "links": [
            28
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionEncode"
      }
    },
    {
      "id": 3,
      "type": "IPAdapterModelLoader",
      "pos": [
        430,
        60
      ],
      "size": [
        270,
        60
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            27
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter_sd15.bin"
      ]
    },
    {
      "id": 7,
      "type": "CheckpointLoaderSimple",
      "pos": [
        380,
        310
      ],
      "size": {
        "0": 315,
        "1": 98
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            30
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            6,
            7
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            13
          ],
          "shape": 3,
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "v1-5-pruned-emaonly.safetensors"
      ]
    },
    {
      "id": 8,
      "type": "CLIPTextEncode",
      "pos": [
        790,
        310
      ],
      "size": {
        "0": 210,
        "1": 76
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 6
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            20
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "a girl with fox ears"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 9,
      "type": "CLIPTextEncode",
      "pos": [
        790,
        430
      ],
      "size": {
        "0": 210,
        "1": 76
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            21
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "horror"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 11,
      "type": "EmptyLatentImage",
      "pos": [
        790,
        560
      ],
      "size": [
        210,
        110
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            11
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        1
      ]
    },
    {
      "id": 10,
      "type": "KSampler",
      "pos": [
        1070,
        320
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 29
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 20
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 21
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 11,
          "slot_index": 3
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            12
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        11,
        "fixed",
        20,
        7,
        "dpmpp_2m",
        "karras",
        1
      ]
    },
    {
      "id": 1,
      "type": "CLIPVisionLoader",
      "pos": [
        30,
        90
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            1
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "IP-Adapter_sd15_pytorch_model.bin"
      ]
    }
  ],
  "links": [
    [
      1,
      1,
      0,
      2,
      0,
      "CLIP_VISION"
    ],
    [
      2,
      6,
      0,
      2,
      1,
      "IMAGE"
    ],
    [
      6,
      7,
      1,
      8,
      0,
      "CLIP"
    ],
    [
      7,
      7,
      1,
      9,
      0,
      "CLIP"
    ],
    [
      11,
      11,
      0,
      10,
      3,
      "LATENT"
    ],
    [
      12,
      10,
      0,
      12,
      0,
      "LATENT"
    ],
    [
      13,
      7,
      2,
      12,
      1,
      "VAE"
    ],
    [
      14,
      12,
      0,
      13,
      0,
      "IMAGE"
    ],
    [
      20,
      8,
      0,
      10,
      1,
      "CONDITIONING"
    ],
    [
      21,
      9,
      0,
      10,
      2,
      "CONDITIONING"
    ],
    [
      27,
      3,
      0,
      17,
      1,
      "IPADAPTER"
    ],
    [
      28,
      2,
      0,
      17,
      2,
      "CLIP_VISION_OUTPUT"
    ],
    [
      29,
      17,
      0,
      10,
      0,
      "MODEL"
    ],
    [
      30,
      7,
      0,
      17,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}