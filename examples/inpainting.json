{
  "last_node_id": 63,
  "last_link_id": 158,
  "nodes": [
    {
      "id": 12,
      "type": "VAEDecode",
      "pos": [
        1650,
        90
      ],
      "size": {
        "0": 140,
        "1": 50
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 12
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            31
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 1,
      "type": "CLIPVisionLoader",
      "pos": [
        230,
        280
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            69
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "IP-Adapter_sd15_pytorch_model.bin"
      ]
    },
    {
      "id": 6,
      "type": "LoadImage",
      "pos": [
        327,
        413
      ],
      "size": {
        "0": 220,
        "1": 314
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            132
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "venere.jpg",
        "image"
      ]
    },
    {
      "id": 59,
      "type": "LoadImage",
      "pos": [
        595,
        548
      ],
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            158
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": [
            157
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "clipspace/clipspace-mask-4664807.png [input]",
        "image"
      ]
    },
    {
      "id": 33,
      "type": "IPAdapterCLIPVisionEncode",
      "pos": [
        590,
        370
      ],
      "size": {
        "0": 253.60000610351562,
        "1": 50
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 69
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 132
        }
      ],
      "outputs": [
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "links": [
            68
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterCLIPVisionEncode"
      }
    },
    {
      "id": 3,
      "type": "IPAdapterModelLoader",
      "pos": [
        583,
        230
      ],
      "size": {
        "0": 270,
        "1": 60
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            45
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-plus-face_sd15.bin"
      ]
    },
    {
      "id": 7,
      "type": "CheckpointLoaderSimple",
      "pos": [
        536,
        68
      ],
      "size": {
        "0": 315,
        "1": 98
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            142
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            6,
            7
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            13,
            155
          ],
          "shape": 3,
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "absolutereality_v181INPAINTING.safetensors"
      ]
    },
    {
      "id": 20,
      "type": "SaveImage",
      "pos": [
        1650,
        190
      ],
      "size": {
        "0": 350,
        "1": 390
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 31
        }
      ],
      "properties": {},
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 63,
      "type": "VAEEncodeForInpaint",
      "pos": [
        968,
        550
      ],
      "size": [
        226.8000030517578,
        98
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 158
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 155
        },
        {
          "name": "mask",
          "type": "MASK",
          "link": 157
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            156
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEEncodeForInpaint"
      },
      "widgets_values": [
        6
      ]
    },
    {
      "id": 31,
      "type": "IPAdapterApply",
      "pos": [
        942,
        77
      ],
      "size": [
        250,
        120
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 142
        },
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 45
        },
        {
          "name": "clip_vision_output",
          "type": "CLIP_VISION_OUTPUT",
          "link": 68
        },
        {
          "name": "mask",
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            150
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        0.8
      ]
    },
    {
      "id": 8,
      "type": "CLIPTextEncode",
      "pos": [
        941,
        253
      ],
      "size": [
        250,
        80
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 6
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            129
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "closeup photo of a blond woman in a forest, professional, detailed, 4k"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 9,
      "type": "CLIPTextEncode",
      "pos": [
        940,
        380
      ],
      "size": [
        250,
        76
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            125
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry, illustration, hat, naked"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 10,
      "type": "KSampler",
      "pos": [
        1290,
        90
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 150
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 129
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 125
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 156,
          "slot_index": 3
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            12
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        45,
        "fixed",
        30,
        7,
        "dpmpp_2m_sde",
        "karras",
        1
      ]
    }
  ],
  "links": [
    [
      6,
      7,
      1,
      8,
      0,
      "CLIP"
    ],
    [
      7,
      7,
      1,
      9,
      0,
      "CLIP"
    ],
    [
      12,
      10,
      0,
      12,
      0,
      "LATENT"
    ],
    [
      13,
      7,
      2,
      12,
      1,
      "VAE"
    ],
    [
      31,
      12,
      0,
      20,
      0,
      "IMAGE"
    ],
    [
      45,
      3,
      0,
      31,
      1,
      "IPADAPTER"
    ],
    [
      68,
      33,
      0,
      31,
      2,
      "CLIP_VISION_OUTPUT"
    ],
    [
      69,
      1,
      0,
      33,
      0,
      "CLIP_VISION"
    ],
    [
      125,
      9,
      0,
      10,
      2,
      "CONDITIONING"
    ],
    [
      129,
      8,
      0,
      10,
      1,
      "CONDITIONING"
    ],
    [
      132,
      6,
      0,
      33,
      1,
      "IMAGE"
    ],
    [
      142,
      7,
      0,
      31,
      0,
      "MODEL"
    ],
    [
      150,
      31,
      0,
      10,
      0,
      "MODEL"
    ],
    [
      155,
      7,
      2,
      63,
      1,
      "VAE"
    ],
    [
      156,
      63,
      0,
      10,
      3,
      "LATENT"
    ],
    [
      157,
      59,
      1,
      63,
      2,
      "MASK"
    ],
    [
      158,
      59,
      0,
      63,
      0,
      "IMAGE"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}